[["index.html", "Introduction to R Course Information R resources Let’s get started", " Introduction to R Nora Wickelmaier 2024-10-11 Course Information This is a two-day course introducing basic R knowledge for the PhD students at the IWM. This book is work in progress. R resources R is a programming language and it takes a while to learn it. It also takes some practice that you will only get while using it – daily if possible. It is also helpful to read through at least one book about R. Here are some suggestions: Navarro, D. (2013). Learning statistics with R. Lulu. com. https://learningstatisticswithr.com/book/ Long, J. D., &amp; Teetor, P. (2019). R Cookbook: Proven recipes for data analysis, statistics, and graphics. 2nd edition. O’Reilly. https://rc2e.com/ Grolemund, G. (2014). Hands-on programming with R. Write your own functions and simulations. O’Reilly. https://rstudio-education.github.io/hopr/ Wickham, H., &amp; Grolemund, G. (2016). R for data science: import, tidy, transform, visualize, and model data (First edition). O’Reilly. http://r4ds.had.co.nz/ Wickham, H. (2019). Advanced R. CRC press. https://adv-r.hadley.nz/ Let’s get started Let us first open an R console. What R version is installed on your system? If it is an old version, you should consider to update it. version ## _ ## platform x86_64-w64-mingw32 ## arch x86_64 ## os mingw32 ## crt ucrt ## system x86_64, mingw32 ## status ## major 4 ## minor 3.3 ## year 2024 ## month 02 ## day 29 ## svn rev 86002 ## language R ## version.string R version 4.3.3 (2024-02-29 ucrt) ## nickname Angel Food Cake You can close R be typing q(). It will ask you, if you want to save the workspace image. Always answer no. This can also be done by saying q(save = \"no\"). In RStudio you might want to go to Tools -&gt; Global Options and then remove the ticks for “Restore .RData into workspace at startup” and “Always save history”. You can also set “Save workspace to .Rdata on exit: Never”. R has an extensive help system. Type ?&lt;function_name&gt; or help(&lt;function_name&gt;) in order to see the documentation for each function. If you are not sure what the function was called use ??&lt;search_term&gt;. Typing help.start() into your R console, opens up inbuilt manuals and FAQ sites. "],["r-as-calculator.html", "Chapter 1 R as calculator", " Chapter 1 R as calculator R is an interactive environment. You can simply use it as a calculator. 2 + 2 ## [1] 4 3 - 7 ## [1] -4 2 * 2 ## [1] 4 4^2 # or 4**2 ## [1] 16 5 / 4 ## [1] 1.25 log(3) ## [1] 1.098612 exp(1) ## [1] 2.718282 In longer equations you can use brackets. sqrt(2) * ((5 - 1/6)^2 - pi/2^(1/3)) ## [1] 29.51128 "],["creating-variables.html", "Chapter 2 Creating variables", " Chapter 2 Creating variables You can store results in a variable using the &lt;- operator. x &lt;- sqrt(2) y &lt;- x^2 ls() ## [1] &quot;x&quot; &quot;y&quot; # rm(list = ls()) # deletes all user defined objects Variable names cannot start with a number. But you can add numbers after a letter, e.g., x1 and x2. "],["data-types.html", "Chapter 3 Data types 3.1 Vectors 3.2 Matrices 3.3 Lists 3.4 Data frames", " Chapter 3 Data types 3.1 Vectors Vectors can be created with the concatenate (or combine) function c(). x &lt;- c(6, 3, 2, 8) x ## [1] 6 3 2 8 You can use mathematical operations element wise on a vector. mean(x) ## [1] 4.75 x + 2 ## [1] 8 5 4 10 sqrt(x) ## [1] 2.449490 1.732051 1.414214 2.828427 y &lt;- c(2, 4) x + y # shorter vector is &quot;recycled&quot; or &quot;broadcasted&quot; ## [1] 8 7 4 12 x + rep(y, 2) ## [1] 8 7 4 12 3.1.1 Creating vectors Vectors can be created in different ways. All objects within one vector must be of the same type. If they are not, R automatically converts all elements to the most general type. Often used types of vectors are character vectors with their elements in quotation marks logical vectors with values TRUE, FALSE and NA (missing values indicated by NA) You can check the type with class() or typeof(). c(&quot;a&quot;, &quot;b&quot;, &quot;c&quot;, 4, 7.7) ## [1] &quot;a&quot; &quot;b&quot; &quot;c&quot; &quot;4&quot; &quot;7.7&quot; seq(1, 2, .1) ## [1] 1.0 1.1 1.2 1.3 1.4 1.5 1.6 1.7 1.8 1.9 2.0 seq(1, 2, length.out = 10) ## [1] 1.000000 1.111111 1.222222 1.333333 1.444444 1.555556 1.666667 1.777778 1.888889 ## [10] 2.000000 seq(from = 1, to = 5, by = 1) ## [1] 1 2 3 4 5 seq(1, 4, along.with = x) ## [1] 1 2 3 4 1:10 ## [1] 1 2 3 4 5 6 7 8 9 10 -5:5 ## [1] -5 -4 -3 -2 -1 0 1 2 3 4 5 rep(1:5, 2) ## [1] 1 2 3 4 5 1 2 3 4 5 rep(c(&quot;a&quot;, &quot;b&quot;, &quot;c&quot;), each = 3) ## [1] &quot;a&quot; &quot;a&quot; &quot;a&quot; &quot;b&quot; &quot;b&quot; &quot;b&quot; &quot;c&quot; &quot;c&quot; &quot;c&quot; rep(c(&quot;a&quot;, &quot;b&quot;, &quot;c&quot;), c(2, 4, 6)) ## [1] &quot;a&quot; &quot;a&quot; &quot;b&quot; &quot;b&quot; &quot;b&quot; &quot;b&quot; &quot;c&quot; &quot;c&quot; &quot;c&quot; &quot;c&quot; &quot;c&quot; &quot;c&quot; table(rep(c(&quot;a&quot;, &quot;b&quot;, &quot;c&quot;), c(2, 4, 6))) ## ## a b c ## 2 4 6 rep(1:4, each = 2, times = 3) # length 24, 3 complete replications ## [1] 1 1 2 2 3 3 4 4 1 1 2 2 3 3 4 4 1 1 2 2 3 3 4 4 rep(rep(1:4, each = 2), 3) # more complicated way ## [1] 1 1 2 2 3 3 4 4 1 1 2 2 3 3 4 4 1 1 2 2 3 3 4 4 paste(&quot;subj&quot;, 1:10, sep = &quot;_&quot;) ## [1] &quot;subj_1&quot; &quot;subj_2&quot; &quot;subj_3&quot; &quot;subj_4&quot; &quot;subj_5&quot; &quot;subj_6&quot; &quot;subj_7&quot; &quot;subj_8&quot; ## [9] &quot;subj_9&quot; &quot;subj_10&quot; weight &lt;- c(60, 72, 57, 90, 95, 72) height &lt;- c(1.75, 1.80, 1.65, 1.90, 1.74, 1.91) plot(height, weight, ylim = c(45, 100)) # logical vectors c(TRUE, FALSE, FALSE, TRUE) ## [1] TRUE FALSE FALSE TRUE weight &gt; 60 ## [1] FALSE TRUE FALSE TRUE TRUE TRUE sum(weight &gt; 60) ## [1] 4 mean(weight &gt; 60) ## [1] 0.6666667 Factors are data structures for categorical variables, such as diagnosis, socio-economic status, sex, etc. ses &lt;- factor(c(&quot;low&quot;, &quot;inter&quot;, &quot;high&quot;)) ses ## [1] low inter high ## Levels: high inter low ses2 &lt;- factor(ses, levels = c(&quot;low&quot;, &quot;inter&quot;, &quot;high&quot;)) ses2 ## [1] low inter high ## Levels: low inter high factor(rep(1:2, each = 10), labels = c(&quot;on&quot;, &quot;of&quot;)) ## [1] on on on on on on on on on on of of of of of of of of of of ## Levels: on of # sort factor levels l &lt;- paste(c(&quot;subj&quot;, &quot;cond&quot;), rep(1:10, each = 2), sep = &quot;_&quot;) f &lt;- factor(l, levels = l) f ## [1] subj_1 cond_1 subj_2 cond_2 subj_3 cond_3 subj_4 cond_4 subj_5 cond_5 subj_6 ## [12] cond_6 subj_7 cond_7 subj_8 cond_8 subj_9 cond_9 subj_10 cond_10 ## 20 Levels: subj_1 cond_1 subj_2 cond_2 subj_3 cond_3 subj_4 cond_4 subj_5 cond_5 ... cond_10 3.2 Matrices R offers multiple functionalities to work with matrices. A &lt;- matrix(1:12, nrow = 3, ncol = 4, byrow = TRUE) A ## [,1] [,2] [,3] [,4] ## [1,] 1 2 3 4 ## [2,] 5 6 7 8 ## [3,] 9 10 11 12 rownames(A) &lt;- c(&quot;a1&quot;, &quot;a2&quot;, &quot;a3&quot;) t(A) ## a1 a2 a3 ## [1,] 1 5 9 ## [2,] 2 6 10 ## [3,] 3 7 11 ## [4,] 4 8 12 diag(A) ## [1] 1 6 11 diag(6) ## [,1] [,2] [,3] [,4] [,5] [,6] ## [1,] 1 0 0 0 0 0 ## [2,] 0 1 0 0 0 0 ## [3,] 0 0 1 0 0 0 ## [4,] 0 0 0 1 0 0 ## [5,] 0 0 0 0 1 0 ## [6,] 0 0 0 0 0 1 diag(c(3, 5, 7)) ## [,1] [,2] [,3] ## [1,] 3 0 0 ## [2,] 0 5 0 ## [3,] 0 0 7 cbind(a1 = 1:4, a2 = 5:8, a3 = 9:12) ## a1 a2 a3 ## [1,] 1 5 9 ## [2,] 2 6 10 ## [3,] 3 7 11 ## [4,] 4 8 12 rbind(a1 = 1:4, a2 = 5:8, a3 = 9:12) ## [,1] [,2] [,3] [,4] ## a1 1 2 3 4 ## a2 5 6 7 8 ## a3 9 10 11 12 5 * A ## [,1] [,2] [,3] [,4] ## a1 5 10 15 20 ## a2 25 30 35 40 ## a3 45 50 55 60 B &lt;- t(A) B %*% A ## [,1] [,2] [,3] [,4] ## [1,] 107 122 137 152 ## [2,] 122 140 158 176 ## [3,] 137 158 179 200 ## [4,] 152 176 200 224 Arrays are data structures having more than two dimensions. array(c(A, 2 * A), c(3, 4, 2)) ## , , 1 ## ## [,1] [,2] [,3] [,4] ## [1,] 1 2 3 4 ## [2,] 5 6 7 8 ## [3,] 9 10 11 12 ## ## , , 2 ## ## [,1] [,2] [,3] [,4] ## [1,] 2 4 6 8 ## [2,] 10 12 14 16 ## [3,] 18 20 22 24 3.3 Lists If it is necessary to store different types of R objects into a single data structure, we need a list. list1 &lt;- list(w = weight, h = height, s = ses2, A = A) list1 ## $w ## [1] 60 72 57 90 95 72 ## ## $h ## [1] 1.75 1.80 1.65 1.90 1.74 1.91 ## ## $s ## [1] low inter high ## Levels: low inter high ## ## $A ## [,1] [,2] [,3] [,4] ## a1 1 2 3 4 ## a2 5 6 7 8 ## a3 9 10 11 12 list1$A ## [,1] [,2] [,3] [,4] ## a1 1 2 3 4 ## a2 5 6 7 8 ## a3 9 10 11 12 list1[[2]] ## [1] 1.75 1.80 1.65 1.90 1.74 1.91 3.4 Data frames Data frames are the fundamental data structure in R. Data frames are lists with the restriction that all list elements (column vectors) have the same length. The rows in a data frame refer to one unit (observation or subject). id &lt;- factor(paste(&quot;s&quot;, 1:6, sep = &quot;&quot;)) dat &lt;- data.frame(id, weight, height) dat ## id weight height ## 1 s1 60 1.75 ## 2 s2 72 1.80 ## 3 s3 57 1.65 ## 4 s4 90 1.90 ## 5 s5 95 1.74 ## 6 s6 72 1.91 dat$id ## [1] s1 s2 s3 s4 s5 s6 ## Levels: s1 s2 s3 s4 s5 s6 Frequently used functions (not only) for data frames are dim(dat) # show number of rows and columns ## [1] 6 3 names(dat) # variable names ## [1] &quot;id&quot; &quot;weight&quot; &quot;height&quot; plot(dat) # pairwise plots str(dat) # show variables of dat ## &#39;data.frame&#39;: 6 obs. of 3 variables: ## $ id : Factor w/ 6 levels &quot;s1&quot;,&quot;s2&quot;,&quot;s3&quot;,..: 1 2 3 4 5 6 ## $ weight: num 60 72 57 90 95 72 ## $ height: num 1.75 1.8 1.65 1.9 1.74 1.91 summary(dat) # descriptive statistics ## id weight height ## s1:1 Min. :57.00 Min. :1.650 ## s2:1 1st Qu.:63.00 1st Qu.:1.742 ## s3:1 Median :72.00 Median :1.775 ## s4:1 Mean :74.33 Mean :1.792 ## s5:1 3rd Qu.:85.50 3rd Qu.:1.875 ## s6:1 Max. :95.00 Max. :1.910 "],["indexing.html", "Chapter 4 Indexing 4.1 Indexing vectors 4.2 Indexing data frames", " Chapter 4 Indexing 4.1 Indexing vectors Elements of a vector can be accessed using [] (see ?Extract). weight[4] ## [1] 90 weight[4] &lt;- 92 weight[c(1, 2, 6)] ## [1] 60 72 72 weight[1:5] ## [1] 60 72 57 92 95 weight[-3] ## [1] 60 72 92 95 72 Indices may be logical. weight[weight &gt; 60] # values greater than 60 ## [1] 72 92 95 72 weight[weight &gt; 60 &amp; weight &lt; 80] # between 60 and 80 ## [1] 72 72 height[weight &gt; 60 &amp; weight &lt; 80] ## [1] 1.80 1.91 4.2 Indexing data frames Data frames have a row and a column index. Omitting one index selects all rows or columns, respectively. dat[3, 2] # 3rd row, 2nd column ## [1] 57 dat[1:4, ] # rows 1 to 4, all columns ## id weight height ## 1 s1 60 1.75 ## 2 s2 72 1.80 ## 3 s3 57 1.65 ## 4 s4 90 1.90 dat[, 3] # all rows, 3rd column ## [1] 1.75 1.80 1.65 1.90 1.74 1.91 dat[dat$id == &quot;s2&quot;, ] # all observations of s2 ## id weight height ## 2 s2 72 1.8 dat[dat$weight &gt; 60, ] # all observations above 60kg ## id weight height ## 2 s2 72 1.80 ## 4 s4 90 1.90 ## 5 s5 95 1.74 ## 6 s6 72 1.91 "],["calling-functions.html", "Chapter 5 Calling functions 5.1 Useful functions", " Chapter 5 Calling functions In R everything is a function. Functions consist of a name a pair of brackets the arguments (none, one, or more) a return value (visible, invisible, NULL). Functions can be called either with positional or with keyword matching. # Keyword matching plot(y = weight, x = height, pch = 16, col = &quot;blue&quot;) # Positional matching plot(height, weight) # see ?plot.default # Mixed plot(height, weight, pch = 16, col = &quot;blue&quot;) Another way to call functions is to use pipes. Pipes are sometimes useful to not store intermediate objects. Sometimes they are better “readable”. dat |&gt; plot(weight ~ height, data = _) 5.1 Useful functions set.seed(1124) # set seed for reproducibility dat2 &lt;- data.frame( id = rep(paste0(&quot;subj&quot;, 1:10), each = 2), cond = factor(rep(c(&quot;c1&quot;, &quot;c2&quot;), each = 10)), time = factor(c(&quot;t1&quot;, &quot;t2&quot;)), iqscore = rnorm(20, mean = 100, sd = 15) ) dat2 ## id cond time iqscore ## 1 subj1 c1 t1 104.50714 ## 2 subj1 c1 t2 74.84047 ## 3 subj2 c1 t1 78.13192 ## 4 subj2 c1 t2 100.21989 ## 5 subj3 c1 t1 115.99902 ## 6 subj3 c1 t2 105.75139 ## 7 subj4 c1 t1 92.50256 ## 8 subj4 c1 t2 105.19623 ## 9 subj5 c1 t1 98.27768 ## 10 subj5 c1 t2 102.94239 ## 11 subj6 c2 t1 128.22955 ## 12 subj6 c2 t2 109.66484 ## 13 subj7 c2 t1 96.73849 ## 14 subj7 c2 t2 97.51510 ## 15 subj8 c2 t1 115.96479 ## 16 subj8 c2 t2 86.68053 ## 17 subj9 c2 t1 98.28299 ## 18 subj9 c2 t2 114.95694 ## 19 subj10 c2 t1 82.90272 ## 20 subj10 c2 t2 96.77230 In R, data from different distributions can be randomly generated. See ?Distributions for a list of the distributions inbuilt in the stats package. All of them follow the same schema: there is a root name (norm for the normal distribution); one can get density values for a certain range with dnorm(), quantiles for certain probability values with qnorm(), probability values for certain quantiles with pnorm() and random numbers drawn from the distribution with rnorm(). # calculating correlation t1 &lt;- dat2[dat2$time == &quot;t1&quot;, &quot;iqscore&quot;] t2 &lt;- dat2[dat2$time == &quot;t2&quot;, &quot;iqscore&quot;] cor.test( ~ t1 + t2) ## ## Pearson&#39;s product-moment correlation ## ## data: t1 and t2 ## t = 0.059322, df = 8, p-value = 0.9542 ## alternative hypothesis: true correlation is not equal to 0 ## 95 percent confidence interval: ## -0.6168009 0.6421175 ## sample estimates: ## cor ## 0.02096875 5.1.1 Function reshape() dat2[order(dat2$time), ] # sort by time ## id cond time iqscore ## 1 subj1 c1 t1 104.50714 ## 3 subj2 c1 t1 78.13192 ## 5 subj3 c1 t1 115.99902 ## 7 subj4 c1 t1 92.50256 ## 9 subj5 c1 t1 98.27768 ## 11 subj6 c2 t1 128.22955 ## 13 subj7 c2 t1 96.73849 ## 15 subj8 c2 t1 115.96479 ## 17 subj9 c2 t1 98.28299 ## 19 subj10 c2 t1 82.90272 ## 2 subj1 c1 t2 74.84047 ## 4 subj2 c1 t2 100.21989 ## 6 subj3 c1 t2 105.75139 ## 8 subj4 c1 t2 105.19623 ## 10 subj5 c1 t2 102.94239 ## 12 subj6 c2 t2 109.66484 ## 14 subj7 c2 t2 97.51510 ## 16 subj8 c2 t2 86.68053 ## 18 subj9 c2 t2 114.95694 ## 20 subj10 c2 t2 96.77230 datw &lt;- reshape(dat2, direction = &quot;wide&quot;, idvar = c(&quot;id&quot;, &quot;cond&quot;), timevar = &quot;time&quot;) names(datw)[3:4] &lt;- c(&quot;t1&quot;, &quot;t2&quot;) cor.test( ~ t1 + t2, datw) ## ## Pearson&#39;s product-moment correlation ## ## data: t1 and t2 ## t = 0.059322, df = 8, p-value = 0.9542 ## alternative hypothesis: true correlation is not equal to 0 ## 95 percent confidence interval: ## -0.6168009 0.6421175 ## sample estimates: ## cor ## 0.02096875 reshape(datw, direction = &quot;long&quot;, varying = 3:4, idvar = &quot;id&quot;, v.names = &quot;iqscore&quot;, times = c(&quot;t1&quot;, &quot;t2&quot;)) ## id cond time iqscore ## subj1.t1 subj1 c1 t1 104.50714 ## subj2.t1 subj2 c1 t1 78.13192 ## subj3.t1 subj3 c1 t1 115.99902 ## subj4.t1 subj4 c1 t1 92.50256 ## subj5.t1 subj5 c1 t1 98.27768 ## subj6.t1 subj6 c2 t1 128.22955 ## subj7.t1 subj7 c2 t1 96.73849 ## subj8.t1 subj8 c2 t1 115.96479 ## subj9.t1 subj9 c2 t1 98.28299 ## subj10.t1 subj10 c2 t1 82.90272 ## subj1.t2 subj1 c1 t2 74.84047 ## subj2.t2 subj2 c1 t2 100.21989 ## subj3.t2 subj3 c1 t2 105.75139 ## subj4.t2 subj4 c1 t2 105.19623 ## subj5.t2 subj5 c1 t2 102.94239 ## subj6.t2 subj6 c2 t2 109.66484 ## subj7.t2 subj7 c2 t2 97.51510 ## subj8.t2 subj8 c2 t2 86.68053 ## subj9.t2 subj9 c2 t2 114.95694 ## subj10.t2 subj10 c2 t2 96.77230 reshape(datw, direction = &quot;long&quot;, varying = c(&quot;t1&quot;, &quot;t2&quot;), idvar = &quot;id&quot;, v.names = &quot;iqscore&quot;, times = c(&quot;t1&quot;, &quot;t2&quot;)) ## id cond time iqscore ## subj1.t1 subj1 c1 t1 104.50714 ## subj2.t1 subj2 c1 t1 78.13192 ## subj3.t1 subj3 c1 t1 115.99902 ## subj4.t1 subj4 c1 t1 92.50256 ## subj5.t1 subj5 c1 t1 98.27768 ## subj6.t1 subj6 c2 t1 128.22955 ## subj7.t1 subj7 c2 t1 96.73849 ## subj8.t1 subj8 c2 t1 115.96479 ## subj9.t1 subj9 c2 t1 98.28299 ## subj10.t1 subj10 c2 t1 82.90272 ## subj1.t2 subj1 c1 t2 74.84047 ## subj2.t2 subj2 c1 t2 100.21989 ## subj3.t2 subj3 c1 t2 105.75139 ## subj4.t2 subj4 c1 t2 105.19623 ## subj5.t2 subj5 c1 t2 102.94239 ## subj6.t2 subj6 c2 t2 109.66484 ## subj7.t2 subj7 c2 t2 97.51510 ## subj8.t2 subj8 c2 t2 86.68053 ## subj9.t2 subj9 c2 t2 114.95694 ## subj10.t2 subj10 c2 t2 96.77230 datl &lt;- reshape(datw, direction = &quot;long&quot;, varying = c(&quot;t1&quot;, &quot;t2&quot;), idvar = &quot;id&quot;, v.names = &quot;iqscore&quot;, times = c(&quot;t1&quot;, &quot;t2&quot;)) datl[order(datl$id), ] ## id cond time iqscore ## subj1.t1 subj1 c1 t1 104.50714 ## subj1.t2 subj1 c1 t2 74.84047 ## subj10.t1 subj10 c2 t1 82.90272 ## subj10.t2 subj10 c2 t2 96.77230 ## subj2.t1 subj2 c1 t1 78.13192 ## subj2.t2 subj2 c1 t2 100.21989 ## subj3.t1 subj3 c1 t1 115.99902 ## subj3.t2 subj3 c1 t2 105.75139 ## subj4.t1 subj4 c1 t1 92.50256 ## subj4.t2 subj4 c1 t2 105.19623 ## subj5.t1 subj5 c1 t1 98.27768 ## subj5.t2 subj5 c1 t2 102.94239 ## subj6.t1 subj6 c2 t1 128.22955 ## subj6.t2 subj6 c2 t2 109.66484 ## subj7.t1 subj7 c2 t1 96.73849 ## subj7.t2 subj7 c2 t2 97.51510 ## subj8.t1 subj8 c2 t1 115.96479 ## subj8.t2 subj8 c2 t2 86.68053 ## subj9.t1 subj9 c2 t1 98.28299 ## subj9.t2 subj9 c2 t2 114.95694 # with more than one independent variable dat2$math &lt;- rnorm(20) dat3 &lt;- reshape(dat2, direction = &quot;wide&quot;, idvar = c(&quot;id&quot;, &quot;cond&quot;), timevar = &quot;time&quot;) reshape(dat3, direction = &quot;long&quot;, varying = list(c(3, 5), c(4, 6)), idvar = &quot;id&quot;, v.names = c(&quot;iqscore&quot;, &quot;math&quot;), times = c(&quot;t1&quot;, &quot;t2&quot;)) ## id cond time iqscore math ## subj1.t1 subj1 c1 t1 104.50714 -0.768464562 ## subj2.t1 subj2 c1 t1 78.13192 0.579968826 ## subj3.t1 subj3 c1 t1 115.99902 1.513784838 ## subj4.t1 subj4 c1 t1 92.50256 -1.208003812 ## subj5.t1 subj5 c1 t1 98.27768 -0.453062994 ## subj6.t1 subj6 c2 t1 128.22955 -1.572056301 ## subj7.t1 subj7 c2 t1 96.73849 0.015114245 ## subj8.t1 subj8 c2 t1 115.96479 -1.192682340 ## subj9.t1 subj9 c2 t1 98.28299 1.652416420 ## subj10.t1 subj10 c2 t1 82.90272 -2.452581136 ## subj1.t2 subj1 c1 t2 74.84047 -1.872061937 ## subj2.t2 subj2 c1 t2 100.21989 -0.457552388 ## subj3.t2 subj3 c1 t2 105.75139 0.731783080 ## subj4.t2 subj4 c1 t2 105.19623 -0.300922946 ## subj5.t2 subj5 c1 t2 102.94239 0.655609659 ## subj6.t2 subj6 c2 t2 109.66484 -0.005842239 ## subj7.t2 subj7 c2 t2 97.51510 -1.307909316 ## subj8.t2 subj8 c2 t2 86.68053 -0.053038257 ## subj9.t2 subj9 c2 t2 114.95694 -0.388632715 ## subj10.t2 subj10 c2 t2 96.77230 -0.805467444 5.1.2 Function aggregate() aggregate(iqscore ~ cond + time, dat2, mean) ## cond time iqscore ## 1 c1 t1 97.88366 ## 2 c2 t1 104.42371 ## 3 c1 t2 97.79008 ## 4 c2 t2 101.11794 aggregate(cbind(iqscore, math) ~ cond + time, dat2, mean) ## cond time iqscore math ## 1 c1 t1 97.88366 -0.06715554 ## 2 c2 t1 104.42371 -0.70995782 ## 3 c1 t2 97.79008 -0.24862891 ## 4 c2 t2 101.11794 -0.51217799 aggregate(cbind(iqscore, math) ~ cond + time, dat2, sd) ## cond time iqscore math ## 1 c1 t1 14.06484 1.1023198 ## 2 c2 t1 17.74710 1.5905592 ## 3 c1 t2 13.01315 1.0560272 ## 4 c2 t2 11.23467 0.5481003 aggregate(cbind(iqscore, math) ~ cond + time, dat2, var) ## cond time iqscore math ## 1 c1 t1 197.8199 1.2151090 ## 2 c2 t1 314.9596 2.5298786 ## 3 c1 t2 169.3421 1.1151934 ## 4 c2 t2 126.2178 0.3004139 aggregate(cbind(iqscore, math) ~ cond + time, dat2, sum) ## cond time iqscore math ## 1 c1 t1 489.4183 -0.3357777 ## 2 c2 t1 522.1185 -3.5497891 ## 3 c1 t2 488.9504 -1.2431445 ## 4 c2 t2 505.5897 -2.5608900 aggregate(cbind(iqscore, math) ~ cond + time, dat2, length) ## cond time iqscore math ## 1 c1 t1 5 5 ## 2 c2 t1 5 5 ## 3 c1 t2 5 5 ## 4 c2 t2 5 5 # Using a customized function ms &lt;- function(x) { m &lt;- mean(x) s &lt;- sd(x) n &lt;- length(x) se &lt;- s/sqrt(n) c(sd = s, mean = m, se = se, n = n) } aggregate(cbind(iqscore, math) ~ cond + time, dat2, ms) ## cond time iqscore.sd iqscore.mean iqscore.se iqscore.n math.sd math.mean ## 1 c1 t1 14.064845 97.883665 6.289990 5.000000 1.10231984 -0.06715554 ## 2 c2 t1 17.747102 104.423708 7.936745 5.000000 1.59055920 -0.70995782 ## 3 c1 t2 13.013151 97.790077 5.819658 5.000000 1.05602717 -0.24862891 ## 4 c2 t2 11.234669 101.117943 5.024297 5.000000 0.54810028 -0.51217799 ## math.se math.n ## 1 0.49297242 5.00000000 ## 2 0.71131970 5.00000000 ## 3 0.47226971 5.00000000 ## 4 0.24511790 5.00000000 "],["data-inputoutput.html", "Chapter 6 Data input/output 6.1 Integrated data sets in R", " Chapter 6 Data input/output The most flexible function to read (text) data into R is read.table(). getwd() # Get working directory ## [1] &quot;C:/Users/nwickelmaier/Nextcloud/Documents/teaching/iwm/R_intro&quot; # setwd() # Set working directory df &lt;- read.table(&quot;data/ourdata.dat&quot;, header = TRUE, stringsAsFactors = TRUE) str(df) ## &#39;data.frame&#39;: 30 obs. of 7 variables: ## $ id : int 1 2 3 4 5 6 7 8 9 10 ... ## $ sex: Factor w/ 2 levels &quot;f&quot;,&quot;m&quot;: 2 2 2 2 2 2 2 2 2 2 ... ## $ age: int 30 40 29 28 39 33 32 38 26 31 ... ## $ mt1: int 3 6 5 5 5 6 5 3 6 6 ... ## $ mt2: int 6 7 6 6 6 5 7 5 3 6 ... ## $ mt3: int 7 3 7 7 1 2 2 1 4 5 ... ## $ mt4: int 4 4 5 5 7 7 4 6 5 5 ... # Fix error df[df$id == 20, &quot;age&quot;] &lt;- 31 write.table(df, &quot;data/ourdata_corr.dat&quot;, row.names = FALSE, quote = FALSE) # SPSS files library(foreign) ds &lt;- read.spss(&quot;data/lowbwt.sav&quot;, to.data.frame = TRUE) ## re-encoding from CP1252 write.csv2(ds, &quot;data/spss_to_excel.csv&quot;) Look up information about read.table() with ?read.table. More information can be found on the slides. 6.1 Integrated data sets in R R has plenty of data sets already available. These data sets can be listed with data(). If all available data sets in all installed packages should be listed use data(package = .packages(all.available = TRUE)). rm(list = ls()) data(cars) ls() ## [1] &quot;cars&quot; #?cars "],["exercises-day-1.html", "Chapter 7 Exercises Day 1", " Chapter 7 Exercises Day 1 Write an executable and commented R script. Essential components Header Set the working directory Useful, short, and precise comments Formal guidelines Rows not longer than 80 symbols Well-arranged code by using indentions and spaces Spaces before and after binary operators (&lt;-, +, -, ~, =, &lt;, &gt;, &lt;=, &gt;=, == etc.) No space between function name and bracket After executing the script (with the function source()) all computations should have been executed and all objects should be available in the working memory. Create two vectors height (in cm) and weight (in kg) with the values \\((159~173~173~184~168~163~180~186~153~174)&#39;\\) and \\((63~73~70~68~67~61~67~74~63~68)&#39;\\). Compute mean, standard deviation, variance, and correlation for both vectors. Create a scatter plot with height on the \\(x\\) axis and weight on the \\(y\\) axis. Use meaningful axis labels. Calculate the body mass index for each subject: \\[ \\text{BMI} = \\frac{\\text{weight in kg}}{\\text{(height~in~m)}^2}. \\] height &lt;- c(159, 173, 173, 184, 168, 163, 180, 186, 153, 174) weight &lt;- c(63, 73, 70, 68, 67, 61, 67, 74, 63, 68) (m_h &lt;- mean(height)) ## [1] 171.3 (s_h &lt;- sd(height)) ## [1] 10.70877 (v_h &lt;- var(height)) ## [1] 114.6778 (m_w &lt;- mean(weight)) ## [1] 67.4 (s_w &lt;- sd(weight)) ## [1] 4.247875 (v_w &lt;- var(weight)) ## [1] 18.04444 (kor &lt;- cor(weight, height)) ## [1] 0.7469363 plot(weight ~ height, xlab = &quot;Height&quot;, ylab = &quot;Weight&quot;) (bmi &lt;- weight/(height/100)^2) ## [1] 24.91990 24.39106 23.38869 20.08507 23.73866 22.95909 20.67901 21.38976 26.91273 ## [10] 22.46003 Create a column vector \\(\\mathbf{x} = (1~5~8~3~7~2~6)&#39;\\). Create another column vector \\(\\mathbf{y}\\) of the same length containing the odd numbers \\(1, 3, 5, \\ldots\\) using the function seq(). Compute a vector \\(\\mathbf{z}\\) as linear combination of \\(\\mathbf{x}\\) and \\(\\mathbf{y}\\): \\(\\mathbf{z} = 4\\mathbf{x} + 2\\mathbf{y}\\). x &lt;- c(1, 5, 8, 3, 7, 2, 6) y &lt;- seq(1, by = 2, along.with = x) z &lt;- 4 * x + 2 * y Combine \\(\\mathbf{x}\\), \\(\\mathbf{y}\\), and \\(\\mathbf{z}\\) into a matrix \\(\\mathbf{A}\\). Treat \\(\\mathbf{x}\\), \\(\\mathbf{y}\\), and \\(\\mathbf{z}\\) as column vectors. Then create a matrix \\(\\mathbf{B}\\) with \\(\\mathbf{x}\\), \\(\\mathbf{y}\\), and \\(\\mathbf{z}\\) as row vectors. Compute the matrix product \\(\\mathbf{B}\\mathbf{A}\\). A &lt;- cbind(x, y, z) B &lt;- t(A) B %*% A ## x y z ## x 188 240 1232 ## y 240 455 1870 ## z 1232 1870 8668 Create a data frame with two independent variables: Hand with levels “right” and “left” and Condition with levels 1, 2, 3, 4, and 5. Simulate reaction times for 50 subjects. Assume reaction time is normally distributed with \\(RT \\sim N(\\mu = 400,\\sigma^2 = 625)\\). There are 10 subjects in each condition. Use functions str() and summary() on your data frame. What does the output tell you? dat &lt;- data.frame( hand = factor(rep(c(&quot;left&quot;,&quot;right&quot;), each = 25), levels = c(&quot;right&quot;,&quot;left&quot;)), cond = factor(rep(1:5, 10)), RT = rnorm(n = 50, mean = 400, sd = sqrt(625)) ) str(dat) ## &#39;data.frame&#39;: 50 obs. of 3 variables: ## $ hand: Factor w/ 2 levels &quot;right&quot;,&quot;left&quot;: 2 2 2 2 2 2 2 2 2 2 ... ## $ cond: Factor w/ 5 levels &quot;1&quot;,&quot;2&quot;,&quot;3&quot;,&quot;4&quot;,..: 1 2 3 4 5 1 2 3 4 5 ... ## $ RT : num 427 433 402 420 376 ... summary(dat) ## hand cond RT ## right:25 1:10 Min. :345.9 ## left :25 2:10 1st Qu.:383.0 ## 3:10 Median :402.3 ## 4:10 Mean :401.9 ## 5:10 3rd Qu.:418.2 ## Max. :452.6 Go to http://socserv.socsci.mcmaster.ca/jfox/Books/Applied-Regression-3E/ and download Vocabulary.txt from the data sets there (Fox, 2008). Store it in a local folder on your computer. Set that folder as your working directory using setwd(). Use read.table() to load this data frame into R’s working memory. Hint: With ?read.table you can get documentation for this function. Find out the number of observations, number of variables, names of variables, descriptive statistics for the dependent variables, and the levels of the factor variables. voc &lt;- read.table(&quot;data/Vocabulary.txt&quot;, header = T, stringsAsFactors = TRUE) dim(voc) ## [1] 21638 5 str(voc) ## &#39;data.frame&#39;: 21638 obs. of 5 variables: ## $ id : int 20040001 20040002 20040003 20040005 20040008 20040010 20040012 20040013 20040016 20040017 ... ## $ year : int 2004 2004 2004 2004 2004 2004 2004 2004 2004 2004 ... ## $ sex : Factor w/ 2 levels &quot;Female&quot;,&quot;Male&quot;: 1 1 2 1 2 2 1 2 2 1 ... ## $ education : int 9 14 14 17 14 14 12 10 11 9 ... ## $ vocabulary: int 3 6 9 8 1 7 6 6 5 1 ... names(voc) ## [1] &quot;id&quot; &quot;year&quot; &quot;sex&quot; &quot;education&quot; &quot;vocabulary&quot; summary(voc) ## id year sex education vocabulary ## Min. :19740001 Min. :1974 Female:12312 Min. : 0.0 Min. : 0.000 ## 1st Qu.:19821102 1st Qu.:1982 Male : 9326 1st Qu.:12.0 1st Qu.: 5.000 ## Median :19891156 Median :1989 Median :12.0 Median : 6.000 ## Mean :19889570 Mean :1989 Mean :12.8 Mean : 5.996 ## 3rd Qu.:19960795 3rd Qu.:1996 3rd Qu.:15.0 3rd Qu.: 7.000 ## Max. :20042811 Max. :2004 Max. :20.0 Max. :10.000 You can use the $-operator to extract single variables from the data frame “Vocabulary.” Extract the variable vocabulary and calculate \\(mean\\) and \\(sd\\) for it. Look at the 217th row of your data frame. What can you tell about that subject? When was this person tested? Sex? How long went this person to school? What score did it have in the vocabulary test? Next, extract only those cases from your data frame that are male, got tested in 1974 and scored below 2 in the vocabulary test. mean(voc$vocabulary) ## [1] 5.996164 sd(voc$vocabulary) ## [1] 2.165205 voc[217,] ## id year sex education vocabulary ## 217 20040401 2004 Female 14 5 voc[voc$year == &quot;1974&quot; &amp; voc$sex == &quot;Male&quot; &amp; voc$vocabulary &lt; 2,] ## id year sex education vocabulary ## 2765 19740016 1974 Male 12 1 ## 2767 19740018 1974 Male 0 1 ## 2839 19740092 1974 Male 4 1 ## 2877 19740131 1974 Male 11 1 ## 2947 19740202 1974 Male 12 1 ## 3106 19740364 1974 Male 11 1 ## 3197 19740456 1974 Male 10 1 ## 3469 19740735 1974 Male 8 1 ## 3569 19740836 1974 Male 7 1 ## 3787 19741065 1974 Male 9 0 ## 3910 19741190 1974 Male 12 1 ## 3916 19741196 1974 Male 6 0 ## 4033 19741315 1974 Male 3 1 ## 4036 19741320 1974 Male 14 1 ## 4042 19741327 1974 Male 2 0 ## 4105 19741391 1974 Male 8 0 ## 4185 19741474 1974 Male 12 0 Sort your data frame in a way that people with the same number of years of education are grouped together; now, within that, group by their score of the vocabulary test. Hint: Use order(). Then you can apply functions head() and tail() to look at the first and last 20 observations, respectively. What do you hypothesize about the relationship of “years of education” and “score in vocabulary test?” head(voc[order(voc$education, voc$vocabulary),], n = 20) ## id year sex education vocabulary ## 9246 19840436 1984 Female 0 0 ## 10908 19870704 1987 Female 0 0 ## 11594 19871441 1987 Male 0 0 ## 11783 19872195 1987 Male 0 0 ## 11902 19872336 1987 Female 0 0 ## 19694 19961907 1996 Female 0 0 ## 2622 20002546 2000 Female 0 1 ## 2767 19740018 1974 Male 0 1 ## 6001 19780377 1978 Male 0 1 ## 7104 19781523 1978 Male 0 1 ## 7401 19820313 1982 Female 0 1 ## 11877 19872308 1987 Female 0 1 ## 11880 19872311 1987 Male 0 1 ## 3024 19740281 1974 Male 0 3 ## 3421 19740686 1974 Male 0 3 ## 4096 19741381 1974 Male 0 3 ## 4862 19760700 1976 Female 0 3 ## 11863 19872294 1987 Male 0 3 ## 17069 19940736 1994 Male 0 4 ## 286 20040528 2004 Male 0 5 tail(voc[order(voc$education, voc$vocabulary),], n = 20) ## id year sex education vocabulary ## 19057 19960918 1996 Male 20 10 ## 19149 19961061 1996 Male 20 10 ## 19292 19961280 1996 Male 20 10 ## 19296 19961288 1996 Male 20 10 ## 19342 19961358 1996 Male 20 10 ## 19343 19961359 1996 Male 20 10 ## 19771 19962028 1996 Male 20 10 ## 19877 19962202 1996 Male 20 10 ## 19975 19962348 1996 Female 20 10 ## 20183 19962672 1996 Male 20 10 ## 20361 19980056 1998 Male 20 10 ## 20470 19980306 1998 Male 20 10 ## 20473 19980313 1998 Female 20 10 ## 20666 19980740 1998 Male 20 10 ## 20706 19980826 1998 Male 20 10 ## 20764 19980952 1998 Female 20 10 ## 21180 19981861 1998 Male 20 10 ## 21225 19981967 1998 Female 20 10 ## 21324 19982182 1998 Female 20 10 ## 21384 19982295 1998 Male 20 10 We now want to know if there are sex differences in “years of education” and “score in vocabulary test.” For that we want to look at the mean scores for men and women separately. Hint: Use aggregate(). You can also look at the means for every year checking if, e.,g., “years of education” have increased within the last couple of decades. aggregate(voc[,4:5], by = list(voc$sex), FUN = mean) ## Group.1 education vocabulary ## 1 Female 12.64352 6.032732 ## 2 Male 12.99517 5.947888 aggregate(voc[,4:5], by = list(voc$year), FUN = mean) ## Group.1 education vocabulary ## 1 1974 11.87483 6.024205 ## 2 1976 11.83473 6.044630 ## 3 1978 12.04380 5.964960 ## 4 1982 12.21126 5.741149 ## 5 1984 12.47575 5.994294 ## 6 1987 12.57177 5.694461 ## 7 1988 12.75326 5.766304 ## 8 1989 12.84401 5.940083 ## 9 1990 13.11620 6.138498 ## 10 1991 12.90219 6.090531 ## 11 1993 13.10365 6.033564 ## 12 1994 13.30543 6.167391 ## 13 1996 13.43676 6.039657 ## 14 1998 13.39047 6.131437 ## 15 2000 13.30587 6.011442 ## 16 2004 13.74965 6.210709 References Fox, J. (2008). Applied regression analysis and generalized linear models. Sage Publications. "],["simple-data-analysis-in-r.html", "Chapter 8 Simple data analysis in R 8.1 t tests 8.2 Linear models 8.3 Analysis of Variance (ANOVA)", " Chapter 8 Simple data analysis in R R is a free software environment for statistical computing and graphics. The stats package, which is automatically loaded when R starts up, contains functions for statistical calculations and random number generation. For a complete list of functions, see library(help = stats). 8.1 t tests # One-sample t test rt &lt;- rnorm(100, mean = 400, sd = 20) t.test(rt, mu = 400) ## ## One Sample t-test ## ## data: rt ## t = -1.701, df = 99, p-value = 0.09208 ## alternative hypothesis: true mean is not equal to 400 ## 95 percent confidence interval: ## 392.2731 400.5938 ## sample estimates: ## mean of x ## 396.4334 # Two-sample t test for independent groups t.test(weight ~ group, PlantGrowth[PlantGrowth$group != &quot;ctrl&quot;, ], var.equal = TRUE) ## ## Two Sample t-test ## ## data: weight by group ## t = -3.0101, df = 18, p-value = 0.007518 ## alternative hypothesis: true difference in means between group trt1 and group trt2 is not equal to 0 ## 95 percent confidence interval: ## -1.4687336 -0.2612664 ## sample estimates: ## mean in group trt1 mean in group trt2 ## 4.661 5.526 # Two-sample t test for dependent groups t.test(extra ~ group, sleep, paired = T) ## ## Paired t-test ## ## data: extra by group ## t = -4.0621, df = 9, p-value = 0.002833 ## alternative hypothesis: true mean difference is not equal to 0 ## 95 percent confidence interval: ## -2.4598858 -0.7001142 ## sample estimates: ## mean difference ## -1.58 8.2 Linear models Let us first fit a simple linear regression. dat &lt;- data.frame( x = c(18, 23, 25, 35, 65, 54, 34, 56, 72, 19, 23, 42, 18, 39, 37), y = c(202, 186, 187, 180, 156, 169, 174, 172, 153, 199, 193, 174, 198, 183, 178) ) lm1 &lt;- lm(y ~ x, dat) plot(y ~ x, dat) abline(lm1) coef(lm1) ## (Intercept) x ## 210.0484584 -0.7977266 predict(lm1) ## 1 2 3 4 5 6 7 8 9 10 ## 195.6894 191.7007 190.1053 182.1280 158.1962 166.9712 182.9258 165.3758 152.6121 194.8917 ## 11 12 13 14 15 ## 191.7007 176.5439 195.6894 178.9371 180.5326 resid(lm1) ## 1 2 3 4 5 6 7 8 ## 6.3106197 -5.7007474 -3.1052943 -2.1280287 -2.1962317 2.0287761 -8.9257552 6.6242292 ## 9 10 11 12 13 14 15 ## 0.3878543 4.1083463 1.2992526 -2.5439427 2.3106197 4.0628776 -2.5325755 names(lm1) ## [1] &quot;coefficients&quot; &quot;residuals&quot; &quot;effects&quot; &quot;rank&quot; &quot;fitted.values&quot; ## [6] &quot;assign&quot; &quot;qr&quot; &quot;df.residual&quot; &quot;xlevels&quot; &quot;call&quot; ## [11] &quot;terms&quot; &quot;model&quot; summary(lm1) ## ## Call: ## lm(formula = y ~ x, data = dat) ## ## Residuals: ## Min 1Q Median 3Q Max ## -8.9258 -2.5383 0.3879 3.1867 6.6242 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 210.04846 2.86694 73.27 &lt; 2e-16 *** ## x -0.79773 0.06996 -11.40 3.85e-08 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 4.578 on 13 degrees of freedom ## Multiple R-squared: 0.9091, Adjusted R-squared: 0.9021 ## F-statistic: 130 on 1 and 13 DF, p-value: 3.848e-08 # model diagnostics par(mfrow = c(2, 2)) plot(lm1) 8.3 Analysis of Variance (ANOVA) An ANOVA is just a special case of a regression where all predictors are categorical. Using the function aov() instead of lm() gives us different results for the extractor functions. dat &lt;- read.table(text = &quot; id group score 1 control 8 2 control 12 3 control 7 4 control 10 5 control 11 6 control 12 7 pro 7 8 pro 9 9 pro 15 10 pro 13 11 pro 11 12 pro 16 13 pro 12 14 pro 8 15 pro 13 16 pro 16 17 contra 4 18 contra 5 19 contra 6 20 contra 3 21 contra 8 22 contra 10 23 contra 3 24 contra 9 &quot;, header = TRUE) aov1 &lt;- aov(score ~ group, data = dat) summary(aov1) ## Df Sum Sq Mean Sq F value Pr(&gt;F) ## group 2 162 81 10.12 0.000834 *** ## Residuals 21 168 8 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 We can again look at the model diagnostics. # model diagnostics par(mfrow = c(2, 2)) plot(aov1) "],["plotting.html", "Chapter 9 Plotting 9.1 Traditional plots 9.2 Lattice plots 9.3 The Grammar of Graphics ggplot2", " Chapter 9 Plotting There are two graphics systems in R Traditional graphics Grid graphics 9.1 Traditional plots plot(cars) Stepwise plotting – first example: dat &lt;- read.table(header = TRUE, text = &quot; A B rt a1 b1 825 a1 b2 792 a1 b3 840 a2 b1 997 a2 b2 902 a2 b3 786 &quot;, stringsAsFactors = TRUE) plot(rt ~ as.numeric(B), dat, type = &quot;n&quot;, axes = FALSE, xlim = c(.8, 3.2), ylim = c(750, 1000), xlab = &quot;Difficulty&quot;, ylab = &quot;Mean reaction time (ms)&quot;) # Plot the data points separately for each level of factor A. points(rt ~ as.numeric(B), dat[dat$A == &quot;a1&quot;, ], type = &quot;b&quot;, pch = 16) points(rt ~ as.numeric(B), dat[dat$A == &quot;a2&quot;, ], type = &quot;b&quot;, pch = 4) # Add axes and a legend. axis(side = 1, at = 1:3, expression(B[1], B[2], B[3])) axis(side = 2) legend(2.5, 975, expression(A[1], A[2]), pch = c(16, 4), bty = &quot;n&quot;, title = &quot;Task&quot;) Second example: plot(Sepal.Length ~ Sepal.Width, iris, axes = FALSE, type = &quot;n&quot;, xlab = &quot;Sepal width&quot;, ylab = &quot;Sepal Length&quot;) points(Sepal.Length ~ Sepal.Width, subset(iris, iris$Species == &quot;setosa&quot;), col = &quot;magenta&quot;, pch = 21) points(Sepal.Length ~ Sepal.Width, subset(iris, iris$Species == &quot;versicolor&quot;), col = &quot;red&quot;, pch = 22) points(Sepal.Length ~ Sepal.Width, subset(iris, iris$Species == &quot;virginica&quot;), col = &quot;purple&quot;, pch = 23) axis(1) axis(2) legend(&quot;topleft&quot;, c(&quot;setosa&quot;, &quot;versicolor&quot;, &quot;virginica&quot;), pch = 21:23, col = c(&quot;magenta&quot;, &quot;red&quot;, &quot;purple&quot;), bty = &quot;n&quot;) lm1 &lt;- lm(Sepal.Length ~ Sepal.Width, subset(iris, iris$Species == &quot;setosa&quot;)) lm2 &lt;- lm(Sepal.Length ~ Sepal.Width, subset(iris, iris$Species == &quot;versicolor&quot;)) lm3 &lt;- lm(Sepal.Length ~ Sepal.Width, subset(iris, iris$Species == &quot;virginica&quot;)) abline(lm1, col = &quot;magenta&quot;) abline(lm2, col = &quot;red&quot;) abline(lm3, col = &quot;purple&quot;) 9.2 Lattice plots The lattice package implements Trellis plots in R. These are plots conditional on other variables. They are perfectly suited for visualizing complex relationships. library(lattice) states &lt;- data.frame(state.x77, state.name = state.name, state.region = state.region) # built-in data sets xyplot(Murder ~ Population | state.region, states) xyplot(Sepal.Length ~ Sepal.Width, iris, groups = Species, type = c(&quot;p&quot;, &quot;r&quot;), auto.key = TRUE) Other example to “quickly” look at data: xyplot(weight ~ Time | Diet, ChickWeight, groups = Chick, type = c(&quot;g&quot;, &quot;p&quot;, &quot;r&quot;)) 9.3 The Grammar of Graphics ggplot2 R has very powerful graphics function. Creating beautiful (publication ready) plots might be one of the best reasons to learn R. The R package ggplot2 gives you endless possibilities. In recent years it has become the state of the art way to create plots in R. It has a steeper learning curve than the functions above (and I recommend to get some knowledge about them, too, so you understand how plotting in R works), but it is well worth the effort to invest some time. A good place to start are the following (online) books: Chang, W. (2018). R graphics cookbook: practical recipes for visualizing data. O’Reilly Media. https://r-graphics.org/ Wickham, H. (2016). ggplot2: elegant graphics for data analysis Springer-Verlag New York. https://ggplot2-book.org/ The grammar of graphics has a simple structure ggplot(data = &lt;DATA&gt;) + &lt;GEOM_FUNCTION&gt;( mapping = aes(&lt;MAPPINGS&gt;), stat = &lt;STAT&gt;, position = &lt;POSITION&gt; ) + &lt;COORDINATE_FUNCTION&gt; + &lt;FACET_FUNCTION&gt; # load package library(ggplot2) # load data data(mpg) # ?mpg mpg ## # A tibble: 234 × 11 ## manufacturer model displ year cyl trans drv cty hwy fl class ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt; &lt;chr&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt; &lt;chr&gt; ## 1 audi a4 1.8 1999 4 auto(l5) f 18 29 p compact ## 2 audi a4 1.8 1999 4 manual(m5) f 21 29 p compact ## 3 audi a4 2 2008 4 manual(m6) f 20 31 p compact ## 4 audi a4 2 2008 4 auto(av) f 21 30 p compact ## 5 audi a4 2.8 1999 6 auto(l5) f 16 26 p compact ## 6 audi a4 2.8 1999 6 manual(m5) f 18 26 p compact ## 7 audi a4 3.1 2008 6 auto(av) f 18 27 p compact ## 8 audi a4 quattro 1.8 1999 4 manual(m5) 4 18 26 p compact ## 9 audi a4 quattro 1.8 1999 4 auto(l5) 4 16 25 p compact ## 10 audi a4 quattro 2 2008 4 manual(m6) 4 20 28 p compact ## # ℹ 224 more rows 9.3.1 Some examples # start your plot with coordinate system ggplot(data = mpg) + geom_point(mapping = aes(x = displ, y = hwy)) + # then add layers theme_bw() # and a theme # even more information ggplot(data = mpg) + geom_point(mapping = aes(x = displ, y = hwy, shape = fl)) What is the difference between these plots? ggplot(data = mpg) + geom_point(mapping = aes(x = displ, y = hwy, color = class)) ggplot(data = mpg) + geom_point(mapping = aes(x = displ, y = hwy), color = &quot;blue&quot;) What happens when we do this? ggplot(data = mpg) + geom_point(mapping = aes(x = displ, y = hwy, color = &quot;blue&quot;)) 9.3.2 Facets Way to visualize additional variables Split plot into several facets Usually only meaningful for categorical variables Used with R’s formula notation y ~ x # one variable ggplot(data = mpg) + geom_point(mapping = aes(x = displ, y = hwy)) + facet_wrap(~ class, nrow = 2) # two variables ggplot(data = mpg) + geom_point(mapping = aes(x = displ, y = hwy)) + facet_grid(drv ~ cyl) 9.3.3 Geometric objects A geom is the geometrical object that a plot uses to represent data For example bar charts, box plots, line charts, … Every geom function takes a mapping argument ggplot2 provides over 40 geoms, and extension packages provide even more (see https://exts.ggplot2.tidyverse.org/gallery/ for a sampling) # scatter plot ggplot(data = mpg) + geom_point(mapping = aes(x = displ, y = hwy)) # fitted line ggplot(data = mpg) + geom_smooth(mapping = aes(x = displ, y = hwy)) ## `geom_smooth()` using method = &#39;loess&#39; and formula = &#39;y ~ x&#39; # add another variable ggplot(data = mpg) + geom_smooth(mapping = aes(x = displ, y = hwy, linetype = drv)) ## `geom_smooth()` using method = &#39;loess&#39; and formula = &#39;y ~ x&#39; # more layers: points and regression lines ggplot(mpg) + geom_point(aes(x = displ, y = hwy, color = drv)) + geom_smooth(aes(x = displ, y = hwy, color = drv), method = &quot;lm&quot;) ## `geom_smooth()` using formula = &#39;y ~ x&#39; "],["exercises-day-2.html", "Chapter 10 Exercises Day 2", " Chapter 10 Exercises Day 2 Write an executable and commented R script. Load the built-in data set . Find out about the data with ?cars. Create a scatter plot of “Distance” as a function of “Speed.” Adjust the size of the margins (mai) and the spacing between labels and axes (mgp). Set type = \"n\" and axes = FALSE and create the plot from scratch, step by step adding points(), axis(), legend(), etc. Export the plot to a png or pdf file. All labels should be readable, so reduce width and height of the output device. par(mai = c(.6,.6,.15,.1), mgp = c(2,.7,0), tck = -.015) plot(cars, type = &quot;n&quot;, axes = FALSE, xlim = c(0, 30), xlab = &quot;Speed (mph)&quot;, ylab = &quot;Stopping distance (ft)&quot;) points(cars, pch = 16) axis(side = 1) axis(side = 2) abline(lm(dist ~ speed, cars), lwd = 2) box(bty = &quot;L&quot;) legend(0, 120, expression(hat(y) == hat(beta)[0] + hat(beta)[1] * Speed), lty = 1, lwd = 2, bty = &quot;n&quot;) Load Vocabulary.txt into R again. Make a scatter plot of “score in vocabulary test” as a function of “years of education.” Set pch = \".\" and use the jitter() function to actually see the structure in the data. Add the mean vocabulary score for each year of education to your plot. Use aggregate() or tapply() to get these means. Add the standard errors (use arrows()). Export the plot to a file. Play with the graphical parameters. The goal is a publication-ready figure. voc &lt;- read.table(&quot;data/Vocabulary.txt&quot;, header = TRUE, stringsAsFactors = TRUE) # calculate standard errors vocm &lt;- aggregate(vocabulary ~ education, voc, mean) vocm$sd &lt;- aggregate(vocabulary ~ education, voc, sd)[,2] vocm$n &lt;- aggregate(vocabulary ~ education, voc, length)[,2] vocm$se &lt;- vocm$sd / sqrt(vocm$n) par(mai = c(.6,.6,.15,.1), mgp = c(2,.7,0), tck = -.015) plot(jitter(vocabulary, 2) ~ jitter(education, 2), voc, pch = &quot;.&quot;, cex = .8, xlab = &quot;Education (in years)&quot;, ylab = &quot;Vocabulary (words correct)&quot;, col = &quot;darkgrey&quot;) points(vocabulary ~ I(0:20), vocm, pch = 16) with(vocm, arrows(0:20, vocabulary + se, 0:20, vocabulary - se, angle = 90, length = .05, code = 3)) # Solution with ggplot() library(ggplot2) ggplot(data = vocm, mapping = aes(x = education, y = vocabulary)) + geom_jitter(data = voc, mapping = aes(x = education, y = vocabulary), pch=&quot;.&quot;, color = &quot;gray&quot;) + labs(x = &quot;Education (in years)&quot;, y = &quot;Vocabulary (words correct)&quot;) + geom_point() + #geom_line() + geom_errorbar(aes(ymin = vocabulary - se, ymax = vocabulary + se), width = 0.5) + theme_bw() Find out if there are sex differences in the relationship of “years of education” and “score in vocabulary test,” and if these differences depend on the year the test was taken in. Load the lattice package and use the xyplot() function. You can also use functions from the ggplot2 package. Hint: Make one scatter plot for each year of education with one regression line for men and one for women. library(lattice) voc$year &lt;- factor(voc$year) xyplot(jitter(vocabulary, 2) ~ jitter(education, 2) | year, data = voc, groups = sex, type = c(&quot;p&quot;, &quot;r&quot;), col = c(&quot;darkgrey&quot;,&quot;black&quot;), pch = &quot;.&quot;, lwd = 2, xlab = &quot;Education (in years)&quot;, ylab = &quot;Vocabulary (words correct)&quot;, lty = 1:2, scales = list(tck = .5, cex = .7), par.strip.text = list(cex = .7), par.settings = list(strip.background = list(col = &quot;lightgrey&quot;)), key = list(lines = list(lwd = 2, col = c(&quot;darkgrey&quot;, &quot;black&quot;), lty = 1:2), text = list(levels(voc$sex)), columns = 2) ) # Solution with ggplot() ggplot(data = voc, mapping = aes(x = education, y = vocabulary, color = sex)) + geom_jitter(pch=&quot;.&quot;) + labs(x = &quot;Education (in years)&quot;, y = &quot;Vocabulary (words correct)&quot;) + stat_smooth(method = &quot;lm&quot;, se = FALSE) + theme_bw() + facet_wrap(vars(year)) Subjects are supposed to solve two mental exercises. Time needed will be measured in minutes. Between the two exercises subjects get a training which is supposed to enhance speed in solving these kind of mental exercises. Ten subjects are tested. The following table shows the solving times: dat &lt;- data.frame( Vp = 1:10, A = c(5.68, 4.52, 5.56, 5.17, 4.67, 5.97, 5.65, 6.04, 4.94, 5.17), B = c(5.45, 4.37, 5.31, 5.19, 4.18, 5.44, 5.19, 5.84, 4.95, 5.04) ) Subj Exercise A Exercise B 1 5.68 5.45 2 4.52 4.37 3 5.56 5.31 4 5.17 5.19 5 4.67 4.18 6 5.97 5.44 7 5.65 5.19 8 6.04 5.84 9 4.94 4.95 10 5.17 5.04 Create a data frame that contains the depicted variables. Use the function reshape() to transform the data frame to the “long” format. dat2 &lt;- reshape(dat, idvar = &quot;Vp&quot;, timevar = &quot;Aufg&quot;, varying = list(2:3), v.names = &quot;Lzeit&quot;, direction = &quot;long&quot;) dat2$Vp &lt;- factor(dat2$Vp) dat2$Aufg &lt;- factor(dat2$Aufg, labels = c(&quot;A&quot;, &quot;B&quot;)) rownames(dat2) &lt;- NULL Plot the solving time for each subject depending on the exercise (one panel per person). Use xyplot() from the lattice package. Export your graphic as a png or pdf file. xyplot(Lzeit ~ Aufg | Vp, dat2, as.table = TRUE, type = c(&quot;g&quot;, &quot;b&quot;), pch = 16, xlab = &quot;Exercise&quot;, ylab = &quot;Solving time (in min)&quot;) Check if the solving times differ for both exercises using a Wilcoxon test (\\(\\alpha = 0.05\\)). with(dat2, wilcox.test(Lzeit[Aufg == &quot;A&quot;], Lzeit[Aufg == &quot;B&quot;], paired = TRUE)) ## ## Wilcoxon signed rank exact test ## ## data: Lzeit[Aufg == &quot;A&quot;] and Lzeit[Aufg == &quot;B&quot;] ## V = 52, p-value = 0.009766 ## alternative hypothesis: true location shift is not equal to 0 Check the same hypothesis using a \\(t\\) test (\\(\\alpha = 0.05\\)). with(dat2, t.test(Lzeit[Aufg == &quot;A&quot;], Lzeit[Aufg == &quot;B&quot;], paired = TRUE)) ## ## Paired t-test ## ## data: Lzeit[Aufg == &quot;A&quot;] and Lzeit[Aufg == &quot;B&quot;] ## t = 3.8808, df = 9, p-value = 0.003727 ## alternative hypothesis: true mean difference is not equal to 0 ## 95 percent confidence interval: ## 0.1005174 0.3814826 ## sample estimates: ## mean difference ## 0.241 For \\(n = 12\\) subjects, intelligence (variable \\(X\\)) and memory performance (variable \\(Y\\)) have been measured. The following value pairs were obtained: dat &lt;- data.frame( Vp = 1:12, int = c(106, 92, 90, 118, 87, 123, 118, 115, 111, 95, 110, 108), mem = c(94, 100, 84, 126, 95, 93, 120, 103, 100, 102, 120, 125) ) \\(X\\) 106 92 90 118 87 123 118 115 111 95 110 108 \\(Y\\) 94 100 84 126 95 93 120 103 100 102 120 125 Create a data frame for these data. Check the normality assumption separately for each variable using quantile-quantile plots. Interpret the results. Plot memory performance depending on intelligence in a scatter plot and add a regression line. Export your graphic as a png or pdf file. Check the hypothesis \\(\\rho_{XY} = 0\\) (if \\(X\\) and \\(Y\\) are uncorrelated) using an appropriate statistical test (\\(\\alpha = 0.05\\)). par(mfrow = c(1, 2), mai = c(.6, .6, .6, .1), mgp = c(2, .7, 0)) qqnorm(dat$int, main = &quot;IQ&quot;) qqline(dat$int) qqnorm(dat$mem, main = &quot;Memory&quot;) qqline(dat$mem) par(mai = c(.6, .6, .1, .1), mgp = c(2, .7, 0)) plot(mem ~ int, dat, xlab = &quot;IQ&quot;, ylab = &quot;Memory&quot;) abline(lm(mem ~ int, dat)) cor.test(~ int + mem, dat, method = &quot;pearson&quot;) ## ## Pearson&#39;s product-moment correlation ## ## data: int and mem ## t = 1.7586, df = 10, p-value = 0.1091 ## alternative hypothesis: true correlation is not equal to 0 ## 95 percent confidence interval: ## -0.1218673 0.8287609 ## sample estimates: ## cor ## 0.4860269 "],["advanced-topics.html", "Chapter 11 Advanced topics 11.1 Programming resources 11.2 Writing Functions 11.3 Conditional execution 11.4 Loops 11.5 Avoiding loops 11.6 Random number generation", " Chapter 11 Advanced topics The following covers some advanced topics on Programming in R that I usually do not cover in the first introduction to R. Most of this is very useful when you want to simulate data in R, e.g., for power simulations. 11.1 Programming resources Some more advanced resources for R programming are the following: Advanced R https://adv-r.hadley.nz/ Happy Git and GitHub for the useR https://happygitwithr.com/ R Programming for Research https://geanders.github.io/RProgrammingForResearch/ Building reproducible analytical pipelines with R https://raps-with-r.dev/ Data Skills for Reproducible Science https://psyteachr.github.io/msc-data-skills/ 11.2 Writing Functions Functions in R consist of a name a pair of brackets the arguments (none, one, or more) a return value (visible, invisible, ) Arguments are passed either without name (in the defined order) -&gt; positional matching or with name (in arbitrary order) -&gt; keyword matching Even if no arguments are passed, the brackets need to be written, e.g., ls(), dir(), getwd() Entering only the name of a function without brackets will display the R code of that function 11.2.1 Implementing a function for a simple two-sample t test Let us implement a simple function ourselves. A function that implements a two-sample t test \\[\\begin{equation*} T = \\frac{\\bar{x} - \\bar{y}} {\\sqrt{\\hat{\\sigma}^2\\, \\left(\\frac{1}{n} + \\frac{1}{m}\\right)}} = \\frac{\\bar{x} - \\bar{y}} {\\sqrt{\\frac{(n-1) \\, s_x^2 + (m-1) \\, s_y^2} {n+m-2}\\cdot \\left(\\frac{1}{n} + \\frac{1}{m}\\right)}} \\end{equation*}\\] with \\[\\begin{equation*} T \\sim t(n+m-2) \\end{equation*}\\] # Example: a handmade t test function twosam &lt;- function(y1, y2){ # definition n1 &lt;- length(y1); n2 &lt;- length(y2) # body yb1 &lt;- mean(y1); yb2 &lt;- mean(y2) s1 &lt;- var(y1); s2 &lt;- var(y2) s &lt;- ((n1 - 1)*s1 + (n2 - 1)*s2)/(n1 + n2 - 2) tst &lt;- (yb1 - yb2)/sqrt(s*(1/n1 + 1/n2)) tst # return value, can also be a list } # Calling the function tstat &lt;- twosam(PlantGrowth$weight[PlantGrowth$group == &quot;ctrl&quot;], PlantGrowth$weight[PlantGrowth$group == &quot;trt1&quot;]) tstat ## [1] 1.19126 11.2.2 Named arguments and defaults If there is a function defined by fun1 &lt;- function(data, data.frame, graph, limit) { ... } then the function may be invoked in several ways, for example fun1(d, df, TRUE, 20) fun1(d, df, graph = TRUE, limit = 20) fun1(data = d, limit = 20, graph = TRUE, data.frame = df) All of them are equivalent (cf. positional matching and keyword matching) In many cases, arguments can be given commonly appropriate default values, in which case they may be omitted altogether from the call fun1 &lt;- function(data, data.frame, graph = TRUE, limit = 20) { ... } It could be called as ans &lt;- fun1(d, df) which is now equivalent to the three cases above, or as ans &lt;- fun1(d, df, limit = 10) which changes one of the defaults. 11.2.3 Exercise Write a function in R that cumulatively sums up the values of vector \\(\\mathbf{x} = (1~2~3~4 \\dots 20)&#39;\\). The result should look like: \\(\\mathbf{y} = (1~3~6~10 \\dots 210)&#39;\\). # TODO: Add solution to exercise 11.3 Conditional execution When programming, a distinction of cases is often necessary for checking of arguments return of error messages interrupting a running process case distinction, e.,g., in mathematical expressions Conditional execution of code is available in R via if(expr_1) { expr_2 } else { expr_3 } where expr_1 must evaluate to a single logical value. x &lt;- 5 # Example 1 if(!is.na(x)) y &lt;- x^2 else stop(&quot;x is missing&quot;) # Example 2 if(x == 5){ # in case x = 5: x &lt;- x + 1 # add 1 to x and y &lt;- 3 # set y to three } else # else: y &lt;- 7 # set y to seven # Example 3 if(x &lt; 99) cat(&quot;x is smaller than 99\\n&quot;) ## x is smaller than 99 ## Vectorized version with ifelse() function # Example 1 ifelse(x == c(5, 6), c(&quot;A1&quot;, &quot;A2&quot;), c(&quot;A3&quot;, &quot;A4&quot;)) ## [1] &quot;A3&quot; &quot;A2&quot; # Example 2 x &lt;- -2:2 ifelse(x &lt; 0, -x, x) ## [1] 2 1 0 1 2 11.3.1 Exercise Implement the following function in R: \\[ f(x) = \\begin{cases} -1 &amp; \\text{if } x &lt; 0,\\\\ 0 &amp; \\text{if } x = 0,\\\\ 1 &amp; \\text{if } x &gt; 0. \\end{cases} \\] # TODO: Add solution to exercise 11.4 Loops Loops are necessary to execute repeating commands Especially for simulations, loops are often used In this case, the same functions or commands are executed for different random numbers There are for() and while() loops for repeated execution The most simple “loop” is replicate() # Example for central limit theorem y &lt;- runif(100) # Draw random numbers hist(y) x &lt;- replicate(1000, mean(runif(100))) hist(x) # Examples repeat and while i &lt;- 0 repeat { i &lt;- i + 1 # Add 1 to i if (i == 3) break # Stop if i = 3 } while (i &gt; 1) { i &lt;- i - 1 # As long as i &gt; 1, subtract 1 } # Example vector operations x &lt;- c(3, 6, 4, 8, 0) # Vector of length 5 for(i in x) print(sqrt(i)) ## [1] 1.732051 ## [1] 2.44949 ## [1] 2 ## [1] 2.828427 ## [1] 0 for(i in seq_along(x)) # Same using indices print(sqrt(x[i])) ## [1] 1.732051 ## [1] 2.44949 ## [1] 2 ## [1] 2.828427 ## [1] 0 for(i in seq_along(x)){ # For all i [1,2,3,4,5]&#39; x[i] &lt;- x[i]^2 # square ith element of x print(x[i]) # and show it on monitor } ## [1] 9 ## [1] 36 ## [1] 16 ## [1] 64 ## [1] 0 x^2 # BETTER ## [1] 81 1296 256 4096 0 11.4.1 Exercise Create a vector \\(\\mathbf{x} = (3~5~7~9~11~13~15~17)&#39;\\) with a for-loop Tip: Use the formula \\(n\\cdot2 + 1\\) Implement two different methods: Allocate memory: Start with a vector of zeros and the correct length and replace its elements iteratively Growing: Start with a NULL object and iteratively add new results Tip: The first method is more efficient, especially for long vectors. # TODO: Add solution to exercise 11.5 Avoiding loops The apply() family of functions may be used in many places where in traditional languages loops are employed. Using vector based alternatives is usually much faster in R. Matrices and arrays: apply() Data frames, lists and vectors: lapply() and sapply() Group-wise calculations: tapply() # Example apply() X &lt;- matrix(c(4, 7, 3, 8, 9, 2, 5, 6, 2, 3, 2, 4), nrow = 3, ncol = 4) # Calculate row maxima res &lt;- numeric(nrow(X)) for(i in 1:nrow(X)){ res[i] &lt;- max(X[i,]) } # or: apply(X, 1, max) # Maximum for each row ## [1] 8 9 4 apply(X, 2, max) # Maximum for each column ## [1] 7 9 6 4 # Example lapply() L &lt;- list(x = 1:10, y = 1:5 + 0i) lapply(L, mean) # Keep list with data type ## $x ## [1] 5.5 ## ## $y ## [1] 3+0i sapply(L, mean) # Create vector, same data type ## x y ## 5.5+0i 3.0+0i sapply(iris, class) # Work column wise on data frame ## Sepal.Length Sepal.Width Petal.Length Petal.Width Species ## &quot;numeric&quot; &quot;numeric&quot; &quot;numeric&quot; &quot;numeric&quot; &quot;factor&quot; # Example tapply() data(Oats, package = &quot;nlme&quot;) with(Oats, tapply(yield, list(Block, Variety), mean)) ## Golden Rain Marvellous Victory ## VI 90.25 109.00 89.50 ## V 95.50 85.25 92.00 ## III 86.75 118.50 82.50 ## IV 108.00 95.00 91.50 ## II 113.25 121.25 87.25 ## I 133.25 129.75 143.00 data(warpbreaks) tapply(warpbreaks$breaks, warpbreaks$tension, sum) ## L M H ## 655 475 390 tapply(warpbreaks$breaks, warpbreaks[ , -1], mean) ## tension ## wool L M H ## A 44.55556 24.00000 24.55556 ## B 28.22222 28.77778 18.77778 11.5.1 Exercise Load the iris data set into R using data(iris) Write a for-loop to calculate the means for the dependent variables (columns 1 to 4) Think of as many vector based alternatives as possible to avoid this loop and calculate the column means # TODO: Add solution to exercise 11.6 Random number generation Most distributions that R handles have four functions. There is a root name, e.g., the root name for the normal distribution is norm. This root is prefixed by one of the letters p, q, d, r. p probability: the cumulative distribution function (CDF) q quantile: the inverse CDF d density: the probability (density) function (PDF) r random: a random variable having the specified distribution See ?Distributions for a list of distributions or the CRAN task view https://cran.r-project.org/view=Distributions. The random number generator in R is seeded: Upon restart of R, new random numbers are generated. To replicate the results of a simulation, the seed (starting value) can be set explicitly with set.seed(). # Examples rnorm(10) # Draw from standard normal distribution ## [1] 0.2675468 1.2276608 0.6615322 -0.8732706 -0.5384081 -0.7154350 -1.5953854 -0.9341066 ## [9] 0.9747744 1.4430671 rpois(10, 1) # Draw from Poisson distribution ## [1] 1 1 0 3 0 1 1 1 2 2 # Sampling with or without replacement from a vector sample(1:5, size = 10, replace = TRUE) ## [1] 3 3 5 4 2 3 4 4 3 5 # Set seed set.seed(1223) # On each run, random numbers will be identical runif(3) ## [1] 0.6289619 0.1267469 0.3285822 11.6.1 Exercise Create a data frame with four variables and 20 observations: \\(X \\sim N(\\mu=100, \\sigma^2=15^2)\\) \\(Y \\sim Bin(n=10, p=0.2)\\) \\(Z \\sim Pois(\\lambda=1)\\) \\(S = X + Y + Z\\) # TODO: Add solution to exercise "],["references.html", "References", " References Anderson, B., Severson, R. &amp; Good, N. (2023). R programming for research. Colorado State University, ERHS 535. https://geanders.github.io/RProgrammingForResearch/ Fox, J. (2008). Applied regression analysis and generalized linear models. Sage Publications. Ligges, U. (2008). Programmieren mit R. Springer-Verlag. Venables, W. N., Smith, D. M., R Development Core Team, et al. (2022). An introduction to R. https://cran.r-project.org/doc/manuals/r-release/R-intro.html Wickham, H. (n.d.). The tidyverse style guide. https://style.tidyverse.org/ "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
